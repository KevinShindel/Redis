{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087aa30e-f8a0-4f37-a28f-a6eb9b2df063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import *\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import TextField, TagField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "REDIS_HOST=\"127.0.0.1\"\n",
    "REDIS_PORT=6379\n",
    "\n",
    "REDIS_URL=os.getenv('REDIS_URL', \"redis://localhost:6379\")\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY', 'your-openai-key')\n",
    "\n",
    "VSS_INDEX_TYPE=\"HNSW\"\n",
    "VSS_DATA_TYPE=\"FLOAT32\"\n",
    "VSS_DISTANCE=\"COSINE\"\n",
    "VSS_DIMENSION=384\n",
    "VSS_MINIMUM_SCORE=2\n",
    "\n",
    "MAX_MOVIES=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdaee35-cf4e-4e5e-998f-54a578477729",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redis.Redis.from_url(REDIS_URL, decode_responses=True)\n",
    "print(conn.ping())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3b95c-330d-4875-a4ef-5742be58ecac",
   "metadata": {},
   "source": [
    "The first thing we'll do is to import the data. For this example, I have chosen a movie database, with an overview, the rating, and additional information that may be useful for searching and filtering our results further. The Kaggle [IMDB movies dataset](https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset) database is in CSV format and ready to import. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a77fe9-5faa-464e-ba7c-e0e906580475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open(\"../../data/movies/imdb_movies.csv\", encoding='utf-8') as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "        cnt = 0\n",
    "        for row in csvReader:\n",
    "            conn.json().set(f'moviebot:movie:{cnt}', '$', row)\n",
    "            cnt = cnt + 1\n",
    "            if (cnt > MAX_MOVIES):\n",
    "                break\n",
    "        print(\"Data was loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b124080-629c-4a2e-8095-10d76cfad0f9",
   "metadata": {},
   "source": [
    "Next, is creating the secondary index on the desired fields, and most important, on the `overview_embedding` field that will store the vector embedding (which we will create in the next step). Read the [documentation](https://redis.io/docs/interact/search-and-query/basic-constructs/field-and-type-options/#vector-fields) to learn more about the supported distances, indexing methods and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdaa2a-7098-4092-ae65-bd3d824b0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index():\n",
    "    indexes = conn.execute_command(\"FT._LIST\")\n",
    "    if \"movie_idx\" not in indexes:\n",
    "        index_def = IndexDefinition(prefix=[\"moviebot:movie:\"], index_type=IndexType.JSON)\n",
    "        schema = (TextField(\"$.crew\", as_name=\"crew\"),\n",
    "                  TextField(\"$.overview\", as_name=\"overview\"),\n",
    "                  TagField(\"$.genre\", as_name=\"genre\"),\n",
    "                  TagField(\"$.names\", as_name=\"names\"),\n",
    "                  VectorField(\"$.overview_embedding\", VSS_INDEX_TYPE, {\"TYPE\": VSS_DATA_TYPE, \"DIM\": VSS_DIMENSION, \"DISTANCE_METRIC\": VSS_DISTANCE}, as_name=\"embedding\"))\n",
    "        conn.ft('movie_idx').create_index(schema, definition=index_def)\n",
    "        print(\"The index has been created\")\n",
    "    else:\n",
    "        print(\"The index exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0a312-dc78-47ea-b34d-9d3e19c23512",
   "metadata": {},
   "source": [
    "The data has been imported and the index created: we can proceed to generate the vector embeddings. For this task, we will use a free embedding model, the [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) Sentence-Transformers model, which maps sentences & paragraphs to a 384-dimensional dense vector space. Note that we want to add the relevant information that may be retrieved later during the semantic search to the index. For this purpose, we will extract and concatenate information such as the movie name, the overview, the genre, the crew, and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d7847-3528-4f9c-a49c-9e80fbf1790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings():\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    for key in conn.scan_iter(match='moviebot:movie:*'):\n",
    "        print(f\"creating the embedding for {key}\")\n",
    "        result = conn.json().get(key, \"$.names\", \"$.overview\", \"$.crew\", \"$.score\", \"$.genre\")\n",
    "        movie = f\"movie title is: {result['$.names'][0]}\\n\"\n",
    "        movie += f\"movie genre is: {result['$.genre'][0]}\\n\"\n",
    "        movie += f\"movie crew is: {result['$.crew'][0]}\\n\"\n",
    "        movie += f\"movie score is: {result['$.score'][0]}\\n\"\n",
    "        movie += f\"movie overview is: {result['$.overview'][0]}\\n\"\n",
    "        conn.json().set(key, \"$.overview_embedding\", model.encode(movie).astype(np.float32).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c42d25-faff-4d55-b7b7-8256455e5cbd",
   "metadata": {},
   "source": [
    "The following function, given the question from the user, performs a semantic search in the database to retrieve relevant information that will be used to construct the prompt. Specifically, we will retrieve the three most relevant movies from the database, and construct a prompt so ChatGPT can define a relevant answer from the provided context. This is probably the most delicate part, which you can change at will to instruct ChatGPT as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739df3db-d187-44ca-bc2c-f57d1cfa1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(model, query):\n",
    "    context = \"\"\n",
    "    prompt = \"\"\n",
    "    q = Query(\"@embedding:[VECTOR_RANGE $radius $vec]=>{$YIELD_DISTANCE_AS: score}\") \\\n",
    "        .sort_by(\"score\", asc=True) \\\n",
    "        .return_fields(\"overview\", \"names\", \"score\", \"$.crew\", \"$.genre\", \"$.score\") \\\n",
    "        .paging(0, 3) \\\n",
    "        .dialect(2)\n",
    "\n",
    "    # Find all vectors within VSS_MINIMUM_SCORE of the query vector\n",
    "    query_params = {\n",
    "        \"radius\": VSS_MINIMUM_SCORE,\n",
    "        \"vec\": model.encode(query).astype(np.float32).tobytes()\n",
    "    }\n",
    "\n",
    "    res = conn.ft(\"movie_idx\").search(q, query_params)\n",
    "\n",
    "    if (res is not None) and len(res.docs):\n",
    "        it = iter(res.docs[0:])\n",
    "        for x in it:\n",
    "            # print(\"the score is: \" + str(x['score']))\n",
    "            movie = f\"movie title is: {x['names']}\\n\"\n",
    "            movie += f\"movie genre is: {x['$.genre']}\\n\"\n",
    "            movie += f\"movie crew is: {x['$.crew']}\\n\"\n",
    "            movie += f\"movie score is: {x['$.score']}\\n\"\n",
    "            movie += f\"movie overview is: {x['overview']}\\n\"\n",
    "            context += movie + \"\\n\"\n",
    "\n",
    "    if len(context) > 0:\n",
    "        prompt = '''Use the provided information to answer the search query the user has sent.\n",
    "            The information in the database provides three movies, choose the one or the ones that fit most.\n",
    "            If you can't answer the user's question, say \"Sorry, I am unable to answer the question, try to refine your question\". Do not guess. You must deduce the answer exclusively from the information provided. \n",
    "            The answer must be formatted in markdown or HTML.\n",
    "            Do not make things up. Do not add personal opinions. Do not add any disclaimer.\n",
    "\n",
    "            Search query: \n",
    "\n",
    "            {}\n",
    "\n",
    "            Information in the database: \n",
    "\n",
    "            {}\n",
    "            '''.format(query, context)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e18c69-bf84-44f4-9273-eff556be595d",
   "metadata": {},
   "source": [
    "The following function is the heart of the interaction with ChatGPT. Here we provide the prompt that was built earlier and forward the answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec0d4f-1293-4eb7-a066-adde4dc1cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpenAIGPT35(prompt):\n",
    "    # Define the system message\n",
    "    system_msg = 'You are a smart and knowledgeable AI assistant with expertise in all kinds of movies. You are a very friendly and helpful AI. You are empowered to recommend movies based on the provided context. Do NOT make anything up. Do NOT engage in topics that are not about movies.';\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0613\")\n",
    "    # print(\"tokens: \" + str(num_tokens_from_string(prompt, \"cl100k_base\")))\n",
    "\n",
    "    try:\n",
    "        openai.api_key=OPENAI_API_KEY\n",
    "        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-0613\",\n",
    "                                                stream=False,\n",
    "                                                messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                                          {\"role\": \"user\", \"content\": prompt}])\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except openai.error.OpenAIError as e:\n",
    "        # Handle the error here\n",
    "        if \"context window is too large\" in str(e):\n",
    "            print(\"Error: Maximum context length exceeded. Please shorten your input.\")\n",
    "            return \"Maximum context length exceeded\"\n",
    "        else:\n",
    "            print(\"An unexpected error occurred:\", e)\n",
    "            return \"An unexpected error occurred\"\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ec396-3064-4784-940b-73a500097ad9",
   "metadata": {},
   "source": [
    "This is an infinite loop that will get questions from the input field and compute the answer. We are not using streaming for simplicity, so the answer may take a few seconds to compute and show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922642c2-1781-4797-bca7-0a15cc29b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render():\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    # React to user input\n",
    "    while True:\n",
    "        question = input(\"Ask a question\\n\")\n",
    "        reply = f\"You asked: {question}\"\n",
    "        prompt = get_prompt(model, question)\n",
    "        response = getOpenAIGPT35(prompt)\n",
    "        print(response)\n",
    "        print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cafca-1c5f-44b7-8bbe-ab37f91f3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "load()\n",
    "create_index()\n",
    "create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6509e-6ec2-40d4-ac14-94b0b7f8289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
